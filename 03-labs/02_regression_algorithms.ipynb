{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_regression_algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "mexScXahRA_x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression algorithms"
      ]
    },
    {
      "metadata": {
        "id": "aRXtJHq6RA_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "\n",
        "The goal of this notebook is to manipulate some regression algorithms using Python. We will use [Pandas](https://pandas.pydata.org/), [Numpy](https://www.numpy.org/), and [scikit-learn](http://scikit-learn.org/stable/documentation.html).\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We willl use the `Boston` dataset. It comprises housing values in suburbs of Boston.\n"
      ]
    },
    {
      "metadata": {
        "id": "l0Y0mJhxRA_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook was created using:\n",
        "    * python 3.7.1\n",
        "    * matplotlib 3.0.2\n",
        "    * pandas 0.23.4\n",
        "    * numpy 1.15.4\n",
        "    * seaborn 0.9.0\n",
        "    * scikit-learn 0.20.1\n",
        "\n",
        "You can check your version of Python by running\n",
        "```python\n",
        "import sys\n",
        "print(sys.version)\n",
        "```\n",
        "\n",
        "and the version of any module by running\n",
        "\n",
        "```python\n",
        "import <module name>\n",
        "print(<module name>.__version__)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "LJWkt1iBRA_2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the libraries to manipulate the data"
      ]
    },
    {
      "metadata": {
        "id": "HuXhL37kRA_3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-SSS4eRRA_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Predicting Housing Price"
      ]
    },
    {
      "metadata": {
        "id": "A3DhSPvpRBAA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Boston house prices dataset\n",
        "---------------------------\n",
        "\n",
        "* **Data Set Characteristics:**  \n",
        "\n",
        "    * Attribute Information (in order):\n",
        "        - `CRIM`:     per capita crime rate by town\n",
        "        - `ZN`:       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - `INDUS`:    proportion of non-retail business acres per town\n",
        "        - `CHAS`:     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - `NOX`:      nitric oxides concentration (parts per 10 million)\n",
        "        - `RM`:       average number of rooms per dwelling\n",
        "        - `AGE`:      proportion of owner-occupied units built prior to 1940\n",
        "        - `DIS`:      weighted distances to five Boston employment centres\n",
        "        - `RAD`:      index of accessibility to radial highways\n",
        "        - `TAX`:      full-value property-tax rate per \\$10,000\n",
        "        - `PTRATIO`:  pupil-teacher ratio by town\n",
        "        - `B`:        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - `LSTAT`:    % lower status of the population\n",
        "        - `MEDV`:     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "References\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann."
      ]
    },
    {
      "metadata": {
        "id": "ryresOSGRBAC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "metadata": {
        "id": "Mp6-Uq_cRBAD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data',\\\n",
        "                 header = None, sep = '\\s+')\n",
        "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',\\\n",
        "              'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nz3dfT9RBAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ND2a688pRBAP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Data preprocessing\n",
        "\n",
        "Counting the number of missing values of each feature"
      ]
    },
    {
      "metadata": {
        "id": "NV-HKMSaRBAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ewTr1NiRBAT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "metadata": {
        "id": "79YsNUEdRBAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set(style = 'whitegrid', context = 'notebook')\n",
        "cols = ['LSTAT', 'INDUS', 'NOX', 'RM', 'MEDV']\n",
        "sns.pairplot(df[cols], height = 2.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lf3dPBfeRBAh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is a linear relationship between **RM** (the average number of rooms per dwelling) and the housing prices **MEDV** (Median value of owner-occupied homes in $1000's). **MEDV** seems to be normally distributed, but it contains outliers"
      ]
    },
    {
      "metadata": {
        "id": "0p_2iQDcRBAj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the linear relationships between the variables through the correlation matrix"
      ]
    },
    {
      "metadata": {
        "id": "31a4KdpKRBAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sns.reset_orig()\n",
        "sns.set(rc={'figure.figsize':(12,9)})\n",
        "correlation_matrix = np.corrcoef(df[df.columns].values.T)\n",
        "# sns.set(font_scale = 1.5)\n",
        "hm = sns.heatmap(data = correlation_matrix,\n",
        "                 annot = True,\n",
        "                 square = True,\n",
        "                 fmt='.2f',\n",
        "                 yticklabels=df.columns,\n",
        "                 xticklabels=df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gW0MgH0_RBAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* **MEDV** is positively high correlated with **RM**(0.7), whereas it has a strong negative correlation with **LSTAT**(-0.74)\n",
        "* Features **RAD** and **Tax** are strongly correlated to each other (0.91). Thus, we should not select these feature together to train the model. The same are valid for features **NOX** and **DIS**, **AGE** and **DIS**, **INDUS** and **DIS**.\n",
        "\n",
        "Let's investigate how **RM** and **LSTAT** vary with **MEDV**"
      ]
    },
    {
      "metadata": {
        "id": "Zeo74-NORBAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "features = ['RM', 'LSTAT']\n",
        "\n",
        "for i, col in enumerate(features):\n",
        "    plt.subplot(1, len(features), i + 1)\n",
        "    plt.scatter(df[col], df['MEDV'])\n",
        "    plt.title(col)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('MEDV')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4ir2jmERBAy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* The price increases as the average number of rooms per dwelling (**RM**) increases. Therefore, there are some outliers\n",
        "* The prices tends to decreases when **LSTAT** increases, although it does not seem to follows a linear relationship  "
      ]
    },
    {
      "metadata": {
        "id": "CLbLwnKPRBAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementing an ordinary least squares (OLS)"
      ]
    },
    {
      "metadata": {
        "id": "zLTI76I_RBA1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Estimating the parameters $\\beta{}$ using sum of squared residuals (SSR), computed as:\n",
        "\n",
        "$$RSS(\\beta{}) = \\min_{\\beta{}\\in{}\\mathbb{R}} \\sum_{i=1}^{N}{(y_i - x_i^T\\beta{})^2}$$"
      ]
    },
    {
      "metadata": {
        "id": "wrkitdrsRBA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearRegressionGD(object):\n",
        "    \n",
        "    def __init__(self, alpha=0.001, n_iter=20):\n",
        "        self.alpha = alpha\n",
        "        self.n_iter = n_iter\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.beta_ = np.zeros(1 + X.shape[1])\n",
        "        self.cost_ = [] \n",
        "        \n",
        "        for i in range(self.n_iter):\n",
        "            output = self.net_input(X)\n",
        "            errors = (y - output)\n",
        "            self.beta_[1:] += self.alpha * X.T.dot(errors)\n",
        "            self.beta_[0]  += self.alpha * errors.sum()\n",
        "            cost = (errors ** 2).sum() / 2.0\n",
        "            self.cost_.append(cost)\n",
        "        return self\n",
        "    \n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.beta_[1:]) + self.beta_[0]\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return self.net_input(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wC0A4v2YRBA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df[['RM']].values\n",
        "y = df['MEDV'].values\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "\n",
        "X_std = sc_x.fit_transform(X)\n",
        "y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-fLpP3jRBA7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating the model"
      ]
    },
    {
      "metadata": {
        "id": "9iPx-JTCRBA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegressionGD()\n",
        "lr_model.fit(X_std, y_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vi8SbCL6RBBC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the cost as a function of the number of epochs"
      ]
    },
    {
      "metadata": {
        "id": "G4jLb876RBBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sns.reset_orig()\n",
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(range(1, lr_model.n_iter+1), lr_model.cost_)\n",
        "plt.ylabel('SSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJkuO_F9RBBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As can be seen, the gradient descent algorithm converged after the fifth epoch"
      ]
    },
    {
      "metadata": {
        "id": "aJUcR6D4RBBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking how well the linear regression model fits the training data"
      ]
    },
    {
      "metadata": {
        "id": "CuLdI7jrRBBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lin_regplot(X, y, model, xlabel='', ylabel=''):\n",
        "    plt.scatter(X, y, c='blue')\n",
        "    plt.plot(X, model.predict(X), color='red')\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    return None\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "lin_regplot(X_std, y_std, lr_model, xlabel = 'RM (standardized)', ylabel = 'MEDV (standardized)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22zvXuRqRBBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* It seems that only the number of rooms is insufficient to explain the price of the houses in different cases.\n",
        "* Likewise, the data suggest that prices may have been clipped. Thus, let's scale the predicted price outcome back on the price in \\$1000's axis, using the **inverse_transform** method of the **_StandardScaler_**"
      ]
    },
    {
      "metadata": {
        "id": "UOcJF5sVRBBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_rooms_std = sc_x.transform(np.array([[5.0]]))\n",
        "# using the trained model to predict the price of a five-rooms house.\n",
        "price_std = lr_model.predict(num_rooms_std) \n",
        "print(\"Price in $1000's: %.3f\" % sc_y.inverse_transform(price_std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yl1Xkfs-RBBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Slope: %.3f' %lr_model.beta_[1])\n",
        "print('Intercept: %.3f' %lr_model.beta_[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8I5snS_RBBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using scikit-learn to estimate the parameters"
      ]
    },
    {
      "metadata": {
        "id": "NwMsHx71RBBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lmodel = LinearRegression()\n",
        "lmodel.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukH68qeIRBBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Slope: %.3f' %lmodel.coef_[0], '\\nIntercept: %.3f' % lmodel.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKUuQsZjRBBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "lin_regplot(X, y, lmodel, 'RM', 'MEDV')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7EY3m_ZRBBq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using RANdom SAmple Consensus (RANSAC) algorithm to fit a robust regression model"
      ]
    },
    {
      "metadata": {
        "id": "x0pSX7fcRBBr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The RANSAC algorithm fits a regression model to a subset of data, aka _inliers_. \n",
        "\n",
        "It can be summarized as follows:\n",
        "\n",
        "1. Select a random number of samples to be inliers and fit the model.\n",
        "2. Test all other data points against the fitted model and those points that fall within a user-given tolerance to the inliers.\n",
        "3. Refit the model using all the inliers.\n",
        "4. Estimate the error of the fitted model versus the inliers.\n",
        "5. Terminate if the performance meets a certain user-defined threshold of if a fixed number of iterations has been reached. Otherwise, returns to step 1."
      ]
    },
    {
      "metadata": {
        "id": "2mmhuWZvRBBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "ransac = RANSACRegressor(base_estimator=LinearRegression(), \n",
        "                         max_trials=100, \n",
        "                         min_samples=50, \n",
        "                         residual_threshold=5.0, \n",
        "                         random_state=10)\n",
        "ransac.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QO7Xc6hcRBB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inlier_mask = ransac.inlier_mask_\n",
        "outlier_mask = np.logical_not(inlier_mask)\n",
        "line_X = np.arange(3,10, 1)\n",
        "line_y_ransac = ransac.predict(line_X[:, np.newaxis])\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.scatter(X[inlier_mask], y[inlier_mask], c='blue', label = 'Inliers')\n",
        "plt.scatter(X[outlier_mask], y[outlier_mask], c='green', label='Outliers', marker='s')\n",
        "plt.plot(line_X, line_y_ransac, color='red')\n",
        "plt.xlabel('RM')\n",
        "plt.ylabel('MEDV')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "print('Slope: %.3f' %ransac.estimator_.coef_[0], '\\nIntercept: %.3f' %ransac.estimator_.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCsSl5_iRBB8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluating the performance of linear models"
      ]
    },
    {
      "metadata": {
        "id": "Ia7XAj95RBB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into training and testing sets"
      ]
    },
    {
      "metadata": {
        "id": "o51RU4SRRBB_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = pd.DataFrame(np.c_[df['LSTAT'], df['RM']], columns = ['LSTAT','RM'])\n",
        "Y = df['MEDV']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, random_state = 10)\n",
        "\n",
        "print(\"X_train = \", X_train.shape, \"X_test = \", X_test.shape, \n",
        "      \"Y_train = \", Y_train.shape, \"Y_test=\",   Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T1M3fM0lRBCE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the linear model"
      ]
    },
    {
      "metadata": {
        "id": "acQFYrN7RBCG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lmodel = LinearRegression()\n",
        "lmodel.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATb6SOYMRBCJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "metadata": {
        "id": "IBOA9L5URBCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_predicted = lmodel.predict(X_train)\n",
        "y_test_predicted  = lmodel.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXJpuY2zRBCN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the residuals"
      ]
    },
    {
      "metadata": {
        "id": "PLDOui2GRBCN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(y_train_predicted, y_train_predicted - Y_train, c='blue', label='Training data')\n",
        "plt.scatter(y_test_predicted, y_test_predicted - Y_test, c='green', marker='s', label='Test data')\n",
        "plt.xlabel('Predicted values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red')\n",
        "plt.xlim([-10,50])\n",
        "plt.ylim([-30,20])\n",
        "plt.legend(loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4hN9ZtgdRBCW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* The model does not seem to be completely wrong, as the residuals are randomly scattered around the centerline.\n",
        "* Therefore, the model is unable to capture some exploratory information, as can be seen in the presence of small patterns\n"
      ]
    },
    {
      "metadata": {
        "id": "T3tJh1PGRBCY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Computing the MSE, RMSE, and $R^2$\n",
        "\n",
        "* The **mean square error (MSE)** is simply the average value of the **residual sum of squares (RSS)** that we minimize to fit the linear regression model. \n",
        "\n",
        "$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2$$\n",
        "\n",
        "* The **root mean square error (RMSE)** comprises the standard deviation of the residuals. It tells us how concentrated the data are around the line of the best fit.\n",
        "\n",
        "$$RMSE = \\sqrt{MSE}$$\n",
        "\n",
        "* The coefficient of determination ($R^2$) represents the fraction of response variance that is captured by the model. It is computed as follows:\n",
        "\n",
        "$$ R^2 = 1 - \\frac{MSE}{Var(y)}$$\n",
        "\n",
        "For the training dataset, $R^2$ is bounded between 0 and 1. Therefore, it can become negative for the test set. If $R^2 = 1$, the model fits the data perfectly, which corresponde a $MSE = 0$.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EOZCfT-kRBCZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse_train = mean_squared_error(Y_train, y_train_predicted)\n",
        "mse_test = mean_squared_error(Y_test, y_test_predicted)\n",
        "\n",
        "print('MSE train: %.3f, test: %.3f' %(mse_train, mse_test))\n",
        "print('RMSE train: %.3f, RMSE test: %.3f' % (np.sqrt(mse_train), np.sqrt(mse_test)))\n",
        "\n",
        "print('R2 score train: %.3f, R2 score test: %.3f' %(r2_score(Y_train, y_train_predicted), \n",
        "                                                    r2_score(Y_test, y_test_predicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}