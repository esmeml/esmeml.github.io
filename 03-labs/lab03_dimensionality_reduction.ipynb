{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "This notebook aims to use **principal component analysis (PCA)** on decathlon's data, which refers to men's  performance during two athletic meetings: [2004 Summer Olympics]\n",
    "(https://en.wikipedia.org/wiki/Athletics_at_the_2004_Summer_Olympics_%E2%80%93_Men%27s_decathlon) and 2004 [Decastar](https://en.wikipedia.org/wiki/Décastar).\n",
    "\n",
    "This notebook was inspired by Chloé-Agathe Azencott and FactoMineR.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. This notebook was created using\n",
    "  * python 3.7.1\n",
    "  * numpy 1.15.4\n",
    "  * matplotlib 3.0.2\n",
    "  * scikit-learn 0.20.1\n",
    "  * seaborn 0.9.0\n",
    "\n",
    "You can check your Python version by running\n",
    "```python\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "and the version of any module by running\n",
    "```python\n",
    "import <module name>\n",
    "print(<module name>.__version__)\n",
    "```\n",
    "\n",
    "### Please complete all the \\# TODOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `matplotlib` for data visualization together with its built-in interface called `pyplot`. Please check https://matplotlib.org/contents.html for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decathlon's dataset\n",
    "\n",
    "The data are available at http://factominer.free.fr/factomethods/datasets/decathlon.txt\n",
    "\n",
    "### Data description\n",
    "\n",
    "* The dataset consists of 41 rows and 13 columns.\n",
    "* The first row is a header describing the content of the columns and the remaining rows refer to the 40 observations (athletes) considered in this dataset.\n",
    "* Columns 1 to 12 are continuous variables: the first ten columns correspond to the performance of the athletes for each event of the decathlon and columns 11 and 12 correspond respectively to the rank and the points obtained.\n",
    "* The last column is a categorical variable corresponding to the athletic meeting (2004 Olympic Games or 2004 Decastar).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df = pd.read_csv('http://factominer.free.fr/factomethods/datasets/decathlon.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the name of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the first five records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decathlon_df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data\n",
    "\n",
    "* We can select a column by name. Note the returned object is also a pandas object (a *series*--a single-columned DataFrame), so we can use the `head()` function to view the first few rows only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decathlon_df['100m'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Or a list for multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df[['100m', '400m']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can check the unique values of a feature (i.e., column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df['Competition'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can select rows satisfying a given condition(s) by passing a boolean series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df[my_data['Competition']=='OlympicG'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To *index* a row, we can use the data frame's `loc` object. This behaves like a dictionary whose keys are the data frame's index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df.loc['CLAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can get an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decathlon_df.describe()  # describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = decathlon_df.values  # get the content of the dataframe as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_df.dtypes  # get the type (dtype) of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic visualization: athletes' performances depending on two disciplines\n",
    "decathlon_df.plot(kind='scatter', x='400m', y='Shot.put', s=50, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scatterplot matrix allows us to visualize:\n",
    "#   * on the diagonal, the density estimation for each of the features\n",
    "#   * on each of the off-diagonal plots, a scatterplot between two of the features. \n",
    "#     Each dot represents a sample.\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(decathlon_df.get(['Shot.put','High.jump', '400m']), alpha=0.2,\n",
    "               figsize=(6, 6), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fancy plot with seaborn : https://seaborn.pydata.org/\n",
    "import seaborn.apionly as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.jointplot('Shot.put', 'High.jump', data = decathlon_df, \n",
    "              kind='kde', height=6, space=0, color='b')\n",
    "\n",
    "# loooking at correlated features\n",
    "sns.jointplot('Shot.put', 'Discus', data = decathlon_df, \n",
    "              kind='reg', height=6, space=0, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns we don't need to represent the athletes\n",
    "new_decathlon_df = decathlon_df.drop(['Points', 'Rank', 'Competition'], axis=1)\n",
    "\n",
    "# Verify new column headers\n",
    "new_decathlon_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the first two principal components of the data\n",
    "\n",
    "We will first implement PCA ourselves. Recall PCA of $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$ finds $M$ principal components as the coluns of $\\mathbf{W} \\in \\mathbb{R}^{D \\times M}$ and a matrix of projected data $\\mathbf{Z} \\in \\mathbb{R}^{N \\times M}$, such that $\\mathbf{Z}\\mathbf{W}^T$ minimises the error as a reconstruction of $\\mathbf{X}$ for the choice of $M$ (equivalently, the factorisation maximally explains the variance in $\\mathbf{X}$). The principal components $\\mathbf{W}$, correspond to the $M$ largest eigenvectors of the empirical covariance matrix $\\boldsymbol\\Sigma = \\frac{1}{N}\\mathbf{X}^T\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Recall that PCA works best on standardised data (mean 0, standard deviation 1). Standardise the data. \n",
    "\n",
    "**Hint**: you should aim to used numpy's vector-based operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the new dataframe to in a numpy array\n",
    "X = new_decathlon_df.values\n",
    "\n",
    "# TODO: standardise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Find the two first components and project the data. These are the two largest eigenvectors of the empirical covariance matrix, $\\boldsymbol\\Sigma = \\frac{1}{N}\\mathbf{X}^T\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "# TODO: calculate the the covariance matrix with numpy\n",
    "\n",
    "# TODO: find its two first principal components\n",
    "\n",
    "# TODO: project X onto the principal components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the projected data. We use a jupyter magic command to display plots inline automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "# create scatterplot on axis N.B. we record the return value to feed to the colorbar\n",
    "cax = ax.scatter(X_projected[:, 0], X_projected[:, 1], c = decathlon_df['Rank'],\n",
    "                 cmap=plt.get_cmap('viridis'))\n",
    "# Set axis limits\n",
    "ax.set_xlim([-5.5, 5.5])\n",
    "ax.set_ylim([-4, 4])\n",
    "# Create color bar\n",
    "plt.colorbar(cax, label='Rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question:** can you recognize a pattern ? Describe what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Answer__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scikit-learn to find the PCs\n",
    "\n",
    "Here, we use scikit-learn to compute the principal components, and compare the results to what we have gotten so far. A useful resource is the online documentation: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = std_scale.transform(X)\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Use `pca.transform` to project the data onto its principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: project X on principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pca.explained_variance_ratio_` gives the percentage of variance explained by each of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How is `pca.explained_variance_ratio_` computed? Check this is the case by computing it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_var = np.var(X_scaled, axis=0).sum()\n",
    "print ( (1 / tot_var) * np.var(X_projected, axis=0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project the data onto its principal components after standardizing.\n",
    " \n",
    "**Question:** Plot the fraction of variance explained by each of the first 10 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the first ten components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(10), pca.explained_variance_ratio_, color='blue')\n",
    "plt.xlim([-1, 9])\n",
    "plt.xlabel(\"Number of PCs\", fontsize=16)\n",
    "plt.ylabel(\"Fraction of variance explained\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the information captured by the principal components, we can consider  `pca.components_`. These are the columns of $\\mathbf{W}$ (for $M = 2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pca.components_\n",
    "print pcs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display each row of $\\mathbf{W}$ in a 2D plot whose x-axis gives its contribution to the first component and y-axis to the second component. Note, whereas before we were visualising the projected data, $\\mathbf{Z}$, now we are visualising the projections, $\\mathbf{W}$. This indicates how the features cluster i.e. if a pair of feature projections are close, observations will tend to be similarly-valued over those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlim([-0.7, 0.7])\n",
    "ax.set_ylim([-0.7, 0.7])\n",
    "\n",
    "for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :])):\n",
    "    # plot line between origin and point (x, y)\n",
    "    ax.plot([0, x], [0, y], color='k')\n",
    "    # display the label of the point\n",
    "    ax.text(x, y, data.columns[i], fontsize='14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** based on the two previous graphs, can you find a meaning for the two principal components ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Singular Value Decomposition for PCA\n",
    "\n",
    "We have seen above that PCA can be performed by computing the eigendecomposition of the covariance matrix. An alternative way of performing PCA is with singular value decomposition (SVD) (https://en.wikipedia.org/wiki/Singular_value_decomposition). SVD effectively generalises the eigendecomposition to non-square matrices, factorising a matrix $\\mathbf{X} \\in \\mathbb{R}^{N\\times M}$ as $\\mathbf{X} = \\mathbf{U}\\mathbf{S}\\mathbf{V}^T$, where $\\mathbf{U} \\in \\mathbb{R}^{N\\times N}$ and $\\mathbf{V} \\in \\mathbb{R}^{D\\times D}$ are orthonormal, and $\\mathbf{S} \\in \\mathbb{R}^{N\\times D}$ is the diagonal matrix of *singular values* with zero rows. Notice that the covariance matrix of $\\mathbf{X}$, $$\\mathbf{\\Sigma} = \\mathbf{X}^T\\mathbf{X} = \\mathbf{V}\\mathbf{S}\\mathbf{U}^T\\mathbf{U}\\mathbf{S}\\mathbf{V}^T = \\mathbf{V}\\mathbf{S}^2\\mathbf{V}^T,$$ which is an eigenvalue decomposition. Hence, there is a strong link between PCA and SVD: $\\mathbf{W} = \\mathbf{U}$ are the principal components and $\\mathbf{Z} = \\mathbf{X}\\mathbf{W}^T = \\mathbf{U}\\mathbf{S}\\mathbf{V}^T\\mathbf{V} = \\mathbf{U}\\mathbf{S}$ are the projected data. Therefore, we can use SVD to perform PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image data\n",
    "\n",
    "For this task, we will use a classic image from image analysis, \"_Lena_\". We start by loading and visualising the image with `imread()` from [imageio](https://pypi.org/project/imageio/) and `imshow()` function from `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "\n",
    "lena = imread('../data/lena.jpg').astype(float)\n",
    "plt.imshow(lena, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the data\n",
    "\n",
    "**Question**: We should first normalise the data by subtracting the mean of each column: $\\mathbf{x}'_{:, i} = \\mathbf{x}_{:, i} - \\frac{1}{N} \\sum\\limits_{i=1}^{N}x_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalise the data prior to SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfom SVD\n",
    "\n",
    "**Question:** use the `svd()` function from numpy.linalg to perform `svd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SVD in numpy. The function should return a tuple U, S, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Reconstruct the *Lena* image from the factorisation. You should plot the reconstruction to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: reconstruct Lena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated SVD\n",
    "\n",
    "To create a lower-rank PCA projection, take the $M$ largest singular values in $\\mathbf{S}$, and the corresponding vectors of $\\mathbf{U}$ and $\\mathbf{V}$. This is equivalent to taking the $M$ largest eigenvectors for PCA, and is known as *truncated SVD*. Note that we are doing PCA on the rows of the image (which are not independent, but this use of PCA as a form of lossy compression is interesting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "for i, M in enumerate([5, 10, 20, 100]):\n",
    "    # TODO: reconstruct X from truncated matrices\n",
    "    \n",
    "    ax = fig.add_subplot(2, 2, i + 1)\n",
    "    ax.imshow(Z, cmap='gray')\n",
    "    ax.set_title('No. components = %d' % M)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you observe? How much compression (in terms of floating point numbers stored) is achieved in each case?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
