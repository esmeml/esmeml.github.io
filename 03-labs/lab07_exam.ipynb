{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Exam\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "This notebook aims to evaluate your understanding of the topics presented during the course **Introduction to Machine Learning**.\n",
    "\n",
    "\n",
    "### Honour Code\n",
    "\n",
    "This is an **individual exam** and you have to follow the following Honour Code:\n",
    "\n",
    "* the answers to the exam must be your own\n",
    "* Any assistance to complete your exam is prohibited\n",
    "* You will not share your answers with other students\n",
    "* You will not look at solutions online\n",
    "* You will be prepared to explain any answer\n",
    "* Your submission may be subject to automated plagiarism detection\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. This notebook was created using\n",
    "  * python 3.7.1\n",
    "  * numpy 1.15.4\n",
    "  * matplotlib 3.0.2\n",
    "  * scikit-learn 0.20.1\n",
    "\n",
    "2. You can check your Python version by running\n",
    "```python\n",
    "import sys\n",
    "print(sys.version)\n",
    "```\n",
    "\n",
    "3. and the version of any module by running\n",
    "```python\n",
    "import <module name>\n",
    "print(<module name>.__version__)\n",
    "```\n",
    "\n",
    "\n",
    "### Submitting your answer\n",
    "\n",
    "* You have **three hours** to complete this exam\n",
    "* Please rename this Jupyter Notebook to **firstname_lastname.ipynb**\n",
    "* Only Jupyter Notebook file is accepted\n",
    "* Only answers submitted through the link: https://forms.gle/7wHocHvv2gA5iqEu8 will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Full name (First and Last name)**:\n",
    "2. **Student ID**:\n",
    "3. **Email**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Telco Customer Churn Dataset\n",
    "\n",
    "The [Telco-churn dataset](https://www.kaggle.com/blastchar/telco-customer-churn) each row represents a customer, and it includes data about customer's subscription for a service. In this case, this dataset comprises information about:\n",
    "\n",
    "* Customers who left within the last month – the column is called Churn\n",
    "* Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "* Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "* Demographic info about customers – gender, age range, and if they have partners and dependents.\n",
    "\n",
    "This dataset contains **7043** rows and **21** features.\n",
    "\n",
    "## Using this dataset, answer the following questions:\n",
    "\n",
    "1. Visualize the univariate distribution of each continuous feature and the distribution of the target.\n",
    "2. Split the dataset into training and test sets. Next, build a pipeline for dealing with categorical features. Then, evaluate the performance of **logistic regression** and **k-nearest neighbors (kNN)** algorithms using **cross-validation**. \n",
    "    * (a) How different are the results? \n",
    "    * (b) How does scaling the continuous features with `StandardScaler` change the results?\n",
    "    \n",
    "3. Do the results improve when the parameters are tuned through `GridSearchCV` of scikit-learn library? Visualise the performance as function of the parameters of the models.\n",
    "4. Visualise the coefficients of the models using the hyper-parameters that performed well in the grid-search strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the telco-churn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv('https://esmeml.github.io/data/telco-customer-churn.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking features' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__TODO__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NHANES Dataset\n",
    "\n",
    "\n",
    "The dataset **NHANES** contains survey data collected by the US National Center for Health Statistics (NCHS), which has conducted a series of health and nutrition surveys since the early 1960's. Since 1999 approximately 5,000 individuals of all ages are interviewed in their homes every year and complete the health examination component of the survey. The health examination is conducted in a mobile examination center (MEC).\n",
    "\n",
    "## Sleep\n",
    "\n",
    "The ability to get a good night's sleep is correlated with many positive health outcomes.  The dataset _NHANES_ contains a binary variable called **SleepTrouble** that indicates whether each person has sleep trouble.\n",
    "\n",
    "For each of the following models, build a classifier for **SleepTrouble** and compare their performance. You may use whatever variable you like, except for **SleepHrsNight**. \n",
    "\n",
    "The models are: \n",
    "  (a) **logistic regression**\n",
    "  (b) **decision tree** \n",
    "  (c) **random forest**\n",
    "  \n",
    "**Compare your results in terms of AUC and average accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the NHANES dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.read_csv('https://esmeml.github.io/data/NHANES.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking features' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__TODO__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finished, please use the link https://forms.gle/7wHocHvv2gA5iqEu8 to submit your Jupyter Notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
